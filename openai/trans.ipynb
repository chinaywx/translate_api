{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看支持的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://api.siliconflow.cn/v1/models\"\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"authorization\": \"Bearer sk-rwdyytsedzlvrkuwxshhkhvehfchnvvwvdcjzqnwgleknhii\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "import json\n",
    "[i['id'] for i in json.loads(response.text).get('data')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多段落翻译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "def genertate_yaml(sens):\n",
    "    yaml_template=''\n",
    "    for i, sen in enumerate(sens):\n",
    "        yaml_template+=f\"\"\"- Id: {i}\\n  Text: {sen.strip()}\\n\"\"\"\n",
    "        if (i + 1) % 50 == 0:\n",
    "                yield yaml.safe_load(yaml_template)\n",
    "                yaml_template=''\n",
    "    if yaml_template:\n",
    "        yield yaml.safe_load(yaml_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sens,target_lang):\n",
    "    results = []\n",
    "    current_response = []\n",
    "    for entry in genertate_yaml(sens):\n",
    "        # print(entry)\n",
    "        prompt = (\n",
    "                f\"You will be given a YAML formatted input containing entries with 'Id' and 'Text' fields. \"\n",
    "                f\"Here is the input:\\n\\n<yaml>\\n{yaml.dump(entry, sort_keys=False,allow_unicode=True)}\\n</yaml>\\n\\n\"\n",
    "                f\"For each entry in the YAML, translate the contents of the 'Text' field into {target_lang}.\"\n",
    "                f\"Write the translation back into the 'Text' field for that entry.\\n\\n\"\n",
    "                f\"<example>\\nInput:\\n- id: 1  text: 'Source'\\nOutput:\\n- id: 1  text:'Translation'\\n</example>\"\n",
    "                f\"Please return the translated YAML directly without wrapping <yaml> tag or include any additional information.\"\n",
    "            )\n",
    "        response = client.chat.completions.create(\n",
    "            model='01-ai/Yi-1.5-34B-Chat-16K',#输入模型名称\n",
    "            messages=[\n",
    "                # {\"role\": \"system\", \"content\": f\"{system}\"},\n",
    "                {'role': 'user', 'content': prompt}\n",
    "            ],\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        # 输出结果\n",
    "        for chunk in response:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            \n",
    "            # 如果content是None，则保存当前的结果并重置current_response\n",
    "            if content is None:\n",
    "                if current_response:\n",
    "                    results.append(''.join(current_response))\n",
    "                    current_response = []\n",
    "            else:\n",
    "                current_response.append(content)\n",
    "        \n",
    "        # 防止最后一个响应没有None时也保存结果\n",
    "        if current_response:\n",
    "            results.append(''.join(current_response))\n",
    "            current_response = []\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(results,sens):\n",
    "    import re\n",
    "    pattern = r\"- Id:\\s*(\\d+)\\s*Text:\\s*(.+)\"\n",
    "    matches = re.findall(pattern, '\\n'.join(results))\n",
    "    data_list = [{\"Id\": int(id_num), \"Text\": text} for id_num, text in matches]\n",
    "    assert len(sens) == len(data_list)\n",
    "    sorted_data_list = sorted(data_list, key=lambda x: x[\"Id\"])\n",
    "    combined_text = \"\\n\".join(item[\"Text\"] for item in sorted_data_list)\n",
    "    return combined_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"sk-rwdyytsedzlvrkuwxshhkhvehfchnvvwvdcjzqnwgleknhii\", base_url=\"https://api.siliconflow.cn/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_lang='english'\n",
    "with open(r'..\\input\\A01B1_06\\0.txt', 'r') as f:\n",
    "    sens = f.readlines()\n",
    "results=translate(sens,target_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text=extract_text(results,sens)\n",
    "with open('input.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(combined_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单段落翻译"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sens,target_lang):\n",
    "    results = []\n",
    "    current_response = []\n",
    "    prompt=(    \n",
    "    f\"Translate the following source text to {target_lang}. \"\n",
    "    f\"Output translation directly without any additional text.\"\n",
    "    f\"\\nSource Text: {sens}\\n\\nTranslated Text:\"\n",
    "    )\n",
    "    response = client.chat.completions.create(\n",
    "        model='01-ai/Yi-1.5-34B-Chat-16K',\n",
    "        messages=[\n",
    "            # {\"role\": \"system\", \"content\": f\"{system}\"},\n",
    "            {'role': 'user', 'content': prompt}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "    for chunk in response:\n",
    "        content = chunk.choices[0].delta.content\n",
    "        \n",
    "        # 如果content是None，则保存当前的结果并重置current_response\n",
    "        if content is None:\n",
    "            if current_response:\n",
    "                results.append(''.join(current_response))\n",
    "                current_response = []\n",
    "        else:\n",
    "            current_response.append(content)\n",
    "    \n",
    "    # 防止最后一个响应没有None时也保存结果\n",
    "    if current_response:\n",
    "        results.append(''.join(current_response))\n",
    "        current_response = []\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"sk-rwdyytsedzlvrkuwxshhkhvehfchnvvwvdcjzqnwgleknhii\", base_url=\"https://api.siliconflow.cn/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_lang='english'\n",
    "sen='本实用新型涉及一种生产用具，尤其涉及一种用于生产的防滑犁头柄。'\n",
    "results=translate(sen,target_lang)\n",
    "for result in results:\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
